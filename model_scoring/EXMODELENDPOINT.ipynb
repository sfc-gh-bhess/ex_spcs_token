{
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  },
  "lastEditStatus": {
   "notebookId": "wd2pmhedyghgdo4lb3ry",
   "authorId": "432459825768",
   "authorName": "BMHESS",
   "authorEmail": "brian.hess@snowflake.com",
   "sessionId": "4e4a94b2-9b64-4a91-91f6-047474abf77c",
   "lastEditTime": 1749577374421
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5c1d6b5-58f2-4fbd-be8c-35643c516e0e",
   "metadata": {
    "name": "Model_Inferencing_Endpoint",
    "collapsed": false
   },
   "source": "# Model Inferencing Endpoint\nThis notebook walks through creating a simple machine learning model, registering it with \nthe Model Registry, and creating a publicly accessible model inferencing endpoint. It then\ndemonstrates how to get programmatic access to the model inferencing endpoint from outside\nof Snowflake using a Programmatic Access Token (PAT)."
  },
  {
   "cell_type": "markdown",
   "id": "74d29d7c-0aed-4ab7-a234-1fdf5b9a8325",
   "metadata": {
    "name": "Setup_Snowflake",
    "collapsed": false
   },
   "source": "## 1. Setup Snowflake\nBefore we proceed, go to the Packages\" pull-down and enter `scikit-learn` in the \"Find Packages\" textbox and select `scikit-learn`. Do the same with `snowflake-ml-python`. Then click \"Save\", which will also restart the Notebook.\n\nFirst we create a database, schema, and role for use in this example."
  },
  {
   "cell_type": "code",
   "id": "8d50cbf4-0c8d-4950-86cb-114990437ac9",
   "metadata": {
    "language": "sql",
    "name": "cell2"
   },
   "source": "USE ROLE accountadmin;\nCREATE ROLE IF NOT EXISTS ml_role;\nGRANT ROLE ml_role TO ROLE ACCOUNTADMIN;\nCREATE DATABASE IF NOT EXISTS api;\nCREATE SCHEMA IF NOT EXISTS api.ml;\nGRANT ALL ON DATABASE api TO ROLE ml_role;\nGRANT ALL ON SCHEMA api.ml TO ROLE ml_role;",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "89689e76-9c9b-4559-a5fa-ad59a0d4709e",
   "metadata": {
    "name": "cell14",
    "collapsed": false
   },
   "source": "Next, let's create a compute pool for our service, and grant usage permissions to our `ML_ROLE` role. \nWe also grant the `ML_ROLE` role the permission to create services with public endpoints."
  },
  {
   "cell_type": "code",
   "id": "c695373e-ac74-4b62-a1f1-08206cbd5c81",
   "metadata": {
    "language": "sql",
    "name": "cell3"
   },
   "source": "USE ROLE accountadmin;\nCREATE COMPUTE POOL IF NOT EXISTS pool_api \n    MIN_NODES = 1\n    MAX_NODES = 1\n    INSTANCE_FAMILY = CPU_X64_XS;\nGRANT ALL ON COMPUTE POOL pool_api TO ROLE ml_role;\nGRANT BIND SERVICE ENDPOINT ON ACCOUNT TO ROLE ml_role;",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "353ea29d-1917-416c-a9ee-76349c67385f",
   "metadata": {
    "name": "cell16",
    "collapsed": false
   },
   "source": "Since we are going to be using Snowpark Container Services to host the inferencing endpoint, we\nwill need an `IMAGE REPOSITORY` to store the model image. We create that using the `ML_ROLE` role."
  },
  {
   "cell_type": "code",
   "id": "9ab3b8ef-36cc-4297-9266-9a96f3bfe8ef",
   "metadata": {
    "language": "sql",
    "name": "cell23"
   },
   "outputs": [],
   "source": "USE ROLE ml_role;\nCREATE IMAGE REPOSITORY IF NOT EXISTS api.ml.repo_ml;",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "5c102ae5-3e15-4f49-83f6-857dcc84b190",
   "metadata": {
    "name": "Create_the_Model",
    "collapsed": false
   },
   "source": "## 2. Create the Model\n\nNow we turn our attention to the actual machine learning model. \n\nFor illustrative purposes, we are creating a simple linear regression model based on the diabetes\ndata set included in Scikit Learn. The example we are using can be found [here](https://scikit-learn.org/1.5/auto_examples/linear_model/plot_ols.html)."
  },
  {
   "cell_type": "code",
   "id": "a70c436c-d669-43c1-be60-3106495c1930",
   "metadata": {
    "language": "python",
    "name": "cell4",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "import numpy as np\n\nfrom sklearn import datasets, linear_model\n\n# Load the diabetes dataset\ndiabetes_X, diabetes_y = datasets.load_diabetes(return_X_y=True)\n\n# Use only one feature\ndiabetes_X = diabetes_X[:, np.newaxis, 2]\n\n# Split the data into training/testing sets\ndiabetes_X_train = diabetes_X[:-20]\ndiabetes_X_test = diabetes_X[-20:]\n\n# Split the targets into training/testing sets\ndiabetes_y_train = diabetes_y[:-20]\ndiabetes_y_test = diabetes_y[-20:]\n\n# Create linear regression object\nregr = linear_model.LinearRegression()\n\n# Train the model using the training sets\nregr.fit(diabetes_X_train, diabetes_y_train)",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "a187477f-dfcf-403d-a437-6f56cdb3ce37",
   "metadata": {
    "name": "cell18",
    "collapsed": false
   },
   "source": "Now that we have created our `regr` linear regression model, let's just test it by calling the `predict()` function directly."
  },
  {
   "cell_type": "code",
   "id": "3d0604c9-a496-4889-b2ad-fdc13e10984d",
   "metadata": {
    "language": "python",
    "name": "cell5"
   },
   "outputs": [],
   "source": "regr.predict([[0.0779]])",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "c0f3410c-9168-46c5-a136-240b7d0c31e1",
   "metadata": {
    "name": "Register_the_Model",
    "collapsed": false
   },
   "source": "## 3. Register the Model\n\nNow we can turn our attention to registering our Scikit Learn model in the Snowflake Model Registry.\n\nFirst, we create a Snowpark Session."
  },
  {
   "cell_type": "code",
   "id": "6356d653-9c93-40d0-b710-3c7fddb50427",
   "metadata": {
    "language": "python",
    "name": "cell1"
   },
   "outputs": [],
   "source": "from snowflake.snowpark.context import get_active_session\nsession = get_active_session()",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "b366e585-e1c1-4256-9699-0ed4a956a96b",
   "metadata": {
    "name": "cell20",
    "collapsed": false
   },
   "source": "Next, we create a Snowflake ML Registry object using the Snowpark Session. We provide the database, `API`, and the schema `ML`."
  },
  {
   "cell_type": "code",
   "id": "0e23cb54-c421-4c0b-bc42-58e5417a3a62",
   "metadata": {
    "language": "python",
    "name": "cell15"
   },
   "outputs": [],
   "source": "from snowflake.ml.registry import Registry\n\nsession.use_schema('API.ML')\nsession.use_role('ML_ROLE')\nreg = Registry(session=session, database_name=\"API\", schema_name=\"ML\")",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "526f1e90-44fd-4f0f-a738-6a68d42fe8f4",
   "metadata": {
    "name": "cell21",
    "collapsed": false
   },
   "source": "Next, we register the `regr` model with the Model Registry. We provide a name for the model (`linreg_diabetes`), a version name (`v1`), and an optional comment. We need to list the Anaconda dependencies for this model (in our case, we just depend on the `scikit-learn` package). We also provide some sample input data so that the schema of the data can be inferred. Lastly, we provide some options to limit warnings.\n\nWe then show the models in the Model Registry."
  },
  {
   "cell_type": "code",
   "id": "6162d40e-c290-4589-b8a1-57416a579460",
   "metadata": {
    "language": "python",
    "name": "cell6"
   },
   "outputs": [],
   "source": "mv = reg.log_model(regr,\n                   model_name=\"linreg_diabetes\",\n                   version_name=\"v1\",\n                   conda_dependencies=[\"scikit-learn\"],\n                   comment=\"Diabetes Linear Regression\",\n                   options={\"relax_version\": True},\n                   sample_input_data=diabetes_X_test)\nreg.show_models()",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "5dd17344-4408-4703-bf31-0554c0e181c1",
   "metadata": {
    "name": "cell22",
    "collapsed": false
   },
   "source": "Now that we have the model registered, we will create a `SERVICE` in Snowpark Container Services (SPCS) to host the inferencing endpoint. We provide a service name (`linreg_diabetes_svc`), a compute pool to use (`pool_api`, which we created earlier), and an image repository to hold the image (`repo_ml`, which we created earlier). Lastly, we indicate that the service should expose the model inferencing endpoint publicly."
  },
  {
   "cell_type": "code",
   "id": "a64aea16-a994-48bf-af76-438f328ff23c",
   "metadata": {
    "language": "python",
    "name": "cell7"
   },
   "outputs": [],
   "source": "# Deploy the model to SPCS\nmv.create_service(\n    service_name=\"linreg_diabetes_svc\",\n    service_compute_pool=\"pool_api\",\n    image_repo=\"API.ML.REPO_ML\",\n    ingress_enabled=True)\n",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "5ce397dc-1676-4ea4-881a-7d94146a87d5",
   "metadata": {
    "name": "Accessing_the_Model_Inferencing_Endpoint",
    "collapsed": false
   },
   "source": "## Accessing the Model Inferencing Endpoint\n\nWe want to set up a separate user and role to access the model inferencing endpoint, as opposed to using the role that created the service.\n\nFirst, we create a new `ML_SCORING_ROLE` role and grant it access to the `API` database and `ML` schema."
  },
  {
   "cell_type": "code",
   "id": "2d08cab7-710f-47a6-ae18-2629cd6d4d11",
   "metadata": {
    "language": "sql",
    "name": "cell10"
   },
   "outputs": [],
   "source": "USE ROLE ACCOUNTADMIN;\nCREATE ROLE IF NOT EXISTS ml_scoring_role;\nGRANT ROLE ml_scoring_role TO ROLE accountadmin;\nGRANT USAGE ON DATABASE api TO ROLE ml_scoring_role;\nGRANT USAGE ON SCHEMA api.ml TO ROLE ml_scoring_role;",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "65d49998-622d-4207-a6a9-83dc3b329d96",
   "metadata": {
    "name": "cell26",
    "collapsed": false
   },
   "source": "Next, we create a user that we can use externally to access the endpoint. This user (`ML_SCORING_USER`) is granted the `ML_SCORING_ROLE` role."
  },
  {
   "cell_type": "code",
   "id": "45a50cb9-41b5-4160-b2be-b129034ea32f",
   "metadata": {
    "language": "sql",
    "name": "cell11"
   },
   "outputs": [],
   "source": "USE ROLE ACCOUNTADMIN;\nCREATE USER IF NOT EXISTS ml_scoring_user PASSWORD='User123' DEFAULT_ROLE = ml_scoring_role\n    DEFAULT_SECONDARY_ROLES = ('ALL') MUST_CHANGE_PASSWORD = FALSE;\nGRANT ROLE ml_scoring_role TO USER ml_scoring_user;",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "a812f54c-55b4-4d17-ae8c-85db1bda5b73",
   "metadata": {
    "name": "cell27",
    "collapsed": false
   },
   "source": "Next, we create a Programmatic Access Token (PAT) that we can use to programmatically access the model inferencing endpoint from outside of Snowflake. \n\nIn order to create a PAT, the user must have a network policy, so we create a network policy that allows access from any source IP address. In practice, this network policy should be set as narrowly as possible. Then, we assign that network policy to our user.\n\nThen, we create a PAT for the `ML_SCORING_USER` user. We will need this token to access from outside Snowflake."
  },
  {
   "cell_type": "code",
   "id": "32e12bd2-ed30-44c7-ab84-94e906670e37",
   "metadata": {
    "language": "sql",
    "name": "cell12"
   },
   "outputs": [],
   "source": "USE ROLE ACCOUNTADMIN;\nCREATE NETWORK POLICY IF NOT EXISTS api_np ALLOWED_IP_LIST = ('0.0.0.0/0');\nALTER USER ml_scoring_user SET NETWORK_POLICY = api_np;\nALTER USER IF EXISTS ml_scoring_user ADD PROGRAMMATIC ACCESS TOKEN ml_scoring_token;",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "c6dd1b72-3ee5-4f04-b3d2-43d67eb26263",
   "metadata": {
    "name": "cell28",
    "collapsed": false
   },
   "source": "We now grant access to the public endpoint to the `ML_SCORING_ROLE`."
  },
  {
   "cell_type": "code",
   "id": "65f29e51-6314-4a30-93c5-a7051484087c",
   "metadata": {
    "language": "sql",
    "name": "cell24"
   },
   "outputs": [],
   "source": "GRANT SERVICE ROLE api.ml.linreg_diabetes_svc!all_endpoints_usage TO ROLE ml_scoring_role;",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "38090062-d4b0-4dea-b9d7-4005986b9f2f",
   "metadata": {
    "name": "cell29",
    "collapsed": false
   },
   "source": "Lastly, we need the actual hostname for the endpoint."
  },
  {
   "cell_type": "code",
   "id": "89ccf59a-e874-445b-b6f0-95074ea13d37",
   "metadata": {
    "language": "sql",
    "name": "cell13"
   },
   "outputs": [],
   "source": "SHOW ENDPOINTS IN SERVICE api.ml.linreg_diabetes_svc;",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "9f6a675e-3b14-4309-8be7-e0bef7ff4b19",
   "metadata": {
    "name": "Access_the_Endpoint_Programmatically",
    "collapsed": false
   },
   "source": "## Access the Endpoint Programmatically\n\nTo access an endpoint in SPCS, we exchange the PAT for a short-lived access token using a Snowflake endpoint. Then we can use that access token to access the endpoint in SPCS. When the access token expires, we can re-exchange the PAT for a new access token. \n\nTo support this pattern, there is [this GitHub repo](https://github.com/sfc-gh-bhess/ex_spcs_token) example we can use. [This blog](https://medium.com/snowflake/programmatic-access-to-snowpark-container-services-b49ef65a7694) post also walks through the details of this pattern, if you want more details.\n\n### Making Requests\nThe model scoring endpoint hosts an path for the scoring function of the model. For example, the `LinearRegression` model in this example has a `predict()` function, which is accessible at the `/predict` path on the ingress endpoint.\n\nThe format for sending in an examplar to be scored and the format of the response are the same as [Snowflake's External Function format](https://docs.snowflake.com/en/sql-reference/external-functions-data-format.html#label-external-functions-data-format). In each call you can submit multiple examplars and get an inference for each examplar. \n\nSpecifically, the input payload is a JSON object with one field named `data` that is an array-of-arrays. Each array in the array-of-arrays is a record where the first element in the array is the index (0-counted) of the exemplar and the subsequent elements are the input arguments to the scoring function. For example, in our example a request to score 3 examplars would look like:\n\n```json\n{\n    \"data\": [\n        [0, 0.070],\n        [1, 0.071],\n        [2, 0.072]\n    ]\n}\n```\n\nThe response is another JSON object with one field named `data` that is an array-of-arrays. Each array in the array-of-arrays is a record where the first element in the array is the index (0-counted) of the input exemplar followed by a JSON object with a key like `output_feature_0` and a value of the score. \n\nThe example return value for the above example would be:\n\n```json\n{\n    \"data\": [\n        [0,{\"output_feature_0\":218.59551211375583}],\n        [1,{\"output_feature_0\":219.53374997500717}],\n        [2,{\"output_feature_0\":220.4719878362585}]\n    ]\n}\n```"
  },
  {
   "cell_type": "markdown",
   "id": "fb26c78c-7cbc-4479-9820-1a1cc1030a7c",
   "metadata": {
    "name": "Example",
    "collapsed": false
   },
   "source": "## Example\nTo make this easy, there are some helper classes in [this GitHub repo](https://github.com/sfc-gh-bhess/ex_spcs_token), as well as a command-line tool. The `PATGenerator` class is the one we will focus on for this example.\n\nYou can install the `snowkey` package from that GitHub repo using:\n```bash\npip install git+https://github.com/sfc-gh-bhess/ex_spcs_token.git\n```\n\nor \n```bash\npipenv install git+https://github.com/sfc-gh-bhess/ex_spcs_token.git#egg=snowkey\n```\n\nThe command-line tool can be tested using our model inferencing endpoint by running the following (execute the following cell to get the specific command line for your example):"
  },
  {
   "cell_type": "code",
   "id": "e026e96b-b0fb-452f-b8b1-1f88f8fe4dbf",
   "metadata": {
    "language": "python",
    "name": "cell9",
    "collapsed": false,
    "codeCollapsed": true
   },
   "outputs": [],
   "source": "import streamlit as st\nfrom snowflake.snowpark.context import get_active_session\nsession = get_active_session()\nidentifier = session.sql(\"SELECT CURRENT_ORGANIZATION_NAME() || '-' || CURRENT_ACCOUNT_NAME() AS identifier\").collect()[0]['IDENTIFIER']\naccount_url = f\"{identifier}.snowflakecomputing.com\"\npat = cell12.to_pandas().iloc[0].to_dict()['token_secret']\nendpoint = cell13.to_pandas().iloc[0].to_dict()['ingress_url']\nrole = \"ML_SCORING_ROLE\"\nscoring_endpoint = f\"https://{endpoint}/predict\"\n\nst.markdown(f\"\"\"\n```bash\npython -m snowkey.spcs_request --account_url '{account_url}' \\\\\n   --pat '{pat}' \\\\\n   --role '{role}' \\\\\n   --url '{scoring_endpoint}' \\\\\n   --method 'POST' \\\\\n   --data '{{\"data\": [[0, 0.070], [1, 0.071], [2, 0.072]]}}'\n```\n\"\"\")",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "a31a5e5a-a75a-4f51-8fd9-a6f9e2ba29bc",
   "metadata": {
    "name": "cell17",
    "collapsed": false
   },
   "source": "Now we show an example of using the Python classes programmatically so you can incorporate it into your code.\n\nRun the following cell to see the code you can use to access the endpoint programmatically in Python. It uses output from previous cells and some SQL to get the values needed in the sample code below."
  },
  {
   "cell_type": "code",
   "id": "606a4366-923d-4c8e-89c4-3f6e6170456c",
   "metadata": {
    "language": "python",
    "name": "cell31",
    "collapsed": false,
    "codeCollapsed": true
   },
   "outputs": [],
   "source": "import streamlit as st\nfrom snowflake.snowpark.context import get_active_session\nsession = get_active_session()\nidentifier = session.sql(\"SELECT CURRENT_ORGANIZATION_NAME() || '-' || CURRENT_ACCOUNT_NAME() AS identifier\").collect()[0]['IDENTIFIER']\npat = cell12.to_pandas().iloc[0].to_dict()['token_secret']\nendpoint = cell13.to_pandas().iloc[0].to_dict()['ingress_url']\nrole = \"ML_SCORING_ROLE\"\nscoring_endpoint = f\"https://{endpoint}/predict\"\n\nst.markdown(f\"\"\"\n```python\nimport requests\nfrom pat_gen import PATGenerator\n\naccount_url = \"{identifier}.snowflakecomputing.com\"\npat = \"{pat}\"\nendpoint = \"https://{endpoint}\"\nrole = \"{role}\"\nscoring_endpoint = \"{scoring_endpoint}\"\n\n# Set up once at the beginning of your program\ngen = PATGenerator(account=account_url,\n                    pat=pat, \n                    endpoint=endpoint, \n                    role=role)\n\n# Each call to the endpoint looks like this:\nresp = requests.post(url=scoring_endpoint, \n                        headers=gen.authorization_header(), \n                        json={{\"data\": [[0, 0.070], [1, 0.071], [2, 0.072]]}})\n\n# Do something with the scores\nscores = resp.json()\n```\n\"\"\")",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "5e23de06-e61b-4c14-bac4-96668086174e",
   "metadata": {
    "name": "Cleanup",
    "collapsed": false
   },
   "source": "## Cleanup\nIf you are finished with this example, we can now delete the scoring service, the model, the user and scoring role."
  },
  {
   "cell_type": "code",
   "id": "0479299c-0eb2-43cd-bf0e-b7e16eb3269d",
   "metadata": {
    "language": "sql",
    "name": "cell33"
   },
   "outputs": [],
   "source": "USE ROLE accountadmin;\nALTER SERVICE api.ml.linreg_diabetes_svc SUSPEND;\nDROP SERVICE api.ml.linreg_diabetes_svc;\nDROP USER ml_scoring_user;\nDROP ROLE ml_scoring_role;\nDROP MODEL api.ml.linreg_diabetes;",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "f8998bb7-04ce-40cb-aeb9-de46fa2ca1d7",
   "metadata": {
    "name": "cell35",
    "collapsed": false
   },
   "source": "You can drop the following resources, as well, but if those are being used for other purposes (e.g., you have other things using the compute pool we created), comment out (or delete) those lines."
  },
  {
   "cell_type": "code",
   "id": "cbb34473-1adc-4574-9829-b2bbed499a8f",
   "metadata": {
    "language": "sql",
    "name": "cell34"
   },
   "outputs": [],
   "source": "USE ROLE accountadmin;\nDROP IMAGE REPOSITORY api.ml.repo_ml;\nDROP COMPUTE POOL pool_api;\nDROP ROLE ml_role;\nDROP SCHEMA api.ml;",
   "execution_count": null
  }
 ]
}